<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">

  <title>Andreas Madsen Portfolio</title>
  <meta name="description" content="Andreas Madsen – PhD candidate at Mila – Machine Learning – Portfolio">
  <meta name="author" content="Andreas Madsen">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#ffffff">
  <meta name="google-site-verification" content="rRROE5I8PhgXZNLztkfC5mpfdCsujNz47kS4wh5gFhY">

  <link rel="shortcut icon" href="data:image/x-icon;," type="image/x-icon">
  <link rel="stylesheet" href="style.css">
  <style>
    /* Store fonts locally. This is a one-page website, so caching fonts for more than
       10 min, is less important than avoiding to create an extra HTTP connection. */
    /* latin, 400 */
    @font-face {
        font-family: 'Raleway';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url('fonts/raleway-v22-latin-regular.woff2') format('woff2');
    }
    /* latin, 600 */
    @font-face {
        font-family: 'Raleway';
        font-style: normal;
        font-weight: 600;
        font-display: swap;
        src: url('fonts/raleway-v22-latin-600.woff2') format('woff2');
    }
    /* latin, 300 */
    @font-face {
        font-family: 'Roboto Slab';
        font-style: normal;
        font-weight: 300;
        font-display: swap;
        src: url('fonts/roboto-slab-v16-latin-300.woff2') format('woff2');
    }
    /* latin, 400 */
    @font-face {
        font-family: 'Roboto Slab';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url('fonts/roboto-slab-v16-latin-regular.woff2') format('woff2');
    }

    html {
        font-family: 'Raleway', sans-serif;
        -webkit-font-smoothing: antialiased;
        -moz-osx-font-smoothing: grayscale;
    }

    header, h1, h2, h3, h4, h5, h6 {
        font-family: 'Roboto Slab', serif;
    }
  </style>
  <script async src="portfolio-filter.js"></script>
</head>
<body>
    <header id="top">
        <h1>Andreas Madsen</h1>
        <ul id="internal-links">
            <li><a href="#about">About</a></li>
            <li><a href="#portfolio">Portfolio</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
        <ul id="external-links">
            <li><a rel="noreferrer" target="_blank" title="Twitter" href="https://twitter.com/andreas_madsen" class="external-twitter"></a></li>
            <li><a rel="noreferrer" target="_blank" title="Google Scholar" href="https://scholar.google.com/citations?hl=en&user=X0zwAXYAAAAJ" class="external-scholar"></a></li>
            <li><a rel="noreferrer" target="_blank" title="GitHub" href="https://github.com/AndreasMadsen" class="external-github"></a></li>
            <li><a rel="noreferrer" target="_blank" title="LinkedIn" href="https://linkedin.com/in/andreasmad" class="external-linkedin"></a></li>
        </ul>
    </header>

    <section class="content" id="about">
        <article id="name">
            <picture>
                <source srcset="me.webp" type="image/webp">
                <source srcset="me.jpg" type="image/jpeg">
                <img class="smaller rounded" alt="Andreas Madsen - Profile Picture" src="me.jpg" width="400" height="400" loading="auto">
            </picture>
            <header>
              <h1 class="name">Andreas Madsen</h1>
              <div class="title">PhD candidate at Mila</div>
              <div class="education">Interpretability, Machine Learning</div>
            </header>
        </article>
        <article id="description">
            <p><strong>
                I'm a PhD candidate at Mila, researching interpretability for Natural Language Processing,
                primarily focusing on ensuring interpretability methods provide valid explanations. My
                supervisors are <a href="http://sarathchandar.in/">prof. Sarath Chandar</a> and <a href="https://sivareddy.in/">prof. Siva Reddy</a>.
                Before that, I was known for being an independent researcher, also in interpretability.
            </strong></p>
            <p>
                Neural networks are very complex, and their logic is not transparent to users or developers.
                Providing explanations of neural networks is called interpretability, and I think that machine
                learning in some areas is socially irresponsible without this. Unfortunately, there
                is not enough research in this area, as most research revolves around beating well-defined benchmarks,
                and "good" explanation is ambiguous. I want to change that. My <em>compass</em> is to ground my
                research in real-world settings based on my 3 years of industry experiences working in machine learning.
            </p>
            <!--<p>
                My direction for my PhD is to develop solid methods for measuring the truthfulness of explanations
                (interpretability-faithfulness). Using the knowledge gained, I will understand what makes explanation
                true to the model's behavior. I belive part of the answer is to bridge the gap between post-hoc and
                intrinsic interpretability.
            </p>-->
            <p>
                During my PhD I have been published in ICML, ACL, EMNLP, ACM, etc. and performed invited talks regarding my work.
                In particular, I was invited by <a href="https://www.sarahooker.me">Sara Hooker</a> to
                do the <a href="https://youtu.be/GFU4ZQ0bxV8">inaugural talk at Cohere for AI</a>.
            </p>
            <p>
                Before starting my PhD I published first in <a href="https://distill.pub/2019/memorization-in-rnns/">
                Distill.pub</a> and later at <a href="https://openreview.net/forum?id=H1gNOeHKPS">ICLR 2020</a>, where
                I received a spotlight award. Both of these works received a lot of attention, and I wrote a
                <a href="https://medium.com/@andreas_madsen/becoming-an-independent-researcher-and-getting-published-in-iclr-with-spotlight-c93ef0b39b8b">
                blog post about my life as an Independent Researcher</a> that went quite viral. All of this also
                    resulted in several interviews and invited talks.
            </p>
            <p>
                In the past, I worked in the industry on Machine Learning for 3 years. One of my
                projects was implementing <a href="https://clinicjs.org/">clinic.js</a>, which has
                become the de-facto profiling tool in JavaScript and won awards. Additionally, I was also
                a very active open-source contributor in JavaScript. I have
                <a href="https://github.com/nodejs/node/commits?author=AndreasMadsen">helped develop
                Node.js since 2011</a> such as: major core components, infrastructure, and I was part of several steering committees.
                Finally, my own open-source modules were
                <a href="https://npm-stat.com/charts.html?author=andreasmadsen&from=2023-01-01&to=2023-12-31">
                downloaded 173 million times in just 2023</a>.
            </p>
        </article>
        <article id="links">
            <ul class="links">
                <li><a rel="noreferrer" target="_blank" href="https://twitter.com/andreas_madsen">Twitter</a></li>
                <li><a rel="noreferrer" target="_blank" href="https://scholar.google.com/citations?hl=en&user=X0zwAXYAAAAJ">Scholar</a></li>
                <li><a rel="noreferrer" target="_blank" href="https://github.com/AndreasMadsen">GitHub</a></li>
                <li><a rel="noreferrer" target="_blank" href="https://linkedin.com/in/andreasmad">LinkedIn</a></li>
            </ul>
        </article>
    </section>

    <section class="content categorized" id="portfolio">
        <h1 class="section-title"><span>Portfolio</span></h1>
        <div id="filter">
            <ul>
                <li class="js-disabled" data-filter-tag="highlights">Highlights</li>
                <li class="js-disabled" data-filter-tag="open_source">Open Source</li>
                <li class="js-disabled" data-filter-tag="products">Products</li>
                <li class="js-disabled" data-filter-tag="publications">Publications</li>
                <li class="js-disabled" data-filter-tag="talks">Talks</li>
            </ul>
        </div>

        <article data-categories="publications highlights">
            <header>
                <h2 class="name">Publication</h2>
                <div class="title">Are self-explanations from Large Language Models faithful? – ACL Findings 2024</div>
                <div class="period">Aug 2024</div>
            </header>
            <img class="smaller" alt="Are self-explanations from Large Language Models faithful?" src="img/2024-self-explain.svg" width="193.8" height="127.1" loading="lazy">
            <div class="description">
                <p>
                    Large language models are increasingly being used by the public, in the form of chat models. These
                    chat systems often provide detailed and highly convincing explanations for their answers, even when
                    not explicitly prompted to do so. This makes users more confident in these models. However, are the
                    explanations true? If not true, this confidence is unsupported which can be dangerous.
                </p>
                <p>
                    We measure the truthfulness (i.e. interpretability-faithfulness) of the explanations that LLMs provide,
                    so called self-explanations. We do so by holding the models accountable to their own explanations,
                    using self-consistency checks. We find that the truthfulness is highly dependent on the model and
                    the specific task. Suggesting we should not have general confidence in these explanations.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://youtu.be/vQjZfnu2DGQ">10 min. video</a></li>
                <li><a rel="noreferrer" href="https://arxiv.org/abs/2401.07927">ArXiv</a></li>
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/llm-introspection">code</a></li>
            </ul>
        </article>
        <article data-categories="publications highlights">
            <header>
                <h2 class="name">Publication</h2>
                <div class="title">Faithfulness Measurable Masked Language Models – ICML 2024</div>
                <div class="period">Jul 2024</div>
            </header>
            <img class="smaller" alt="Faithfulness Measurable Masked Language Models" src="img/2023-fmm.svg" width="308" height="157" loading="lazy">
            <div class="description">
                <p>
                    Interpretability have two paradigms, post-hoc or intrinsic explanations. This paper propose a
                    new paradigm, where models intrinsically provides the means to measure faithfulness of any
                    explanation. We call these inherently faithfulness measurable models (FMMs).
                </p>
                <p>
                    Because measuring faithfulness is now trivial, it is possible to optimize explanations with
                    respect to the faithfulness. As a result, the model becomes indirectly inherently explainable and
                    we get explanations with state-of-the-art faithfulness scores.
                </p>
                <p>
                    We demonstrate this general idea using masked language model (MLM), by simply fine-tuning an
                    MLM such that masking any tokens are in-distribution. We thoroughly validate our claims on 16
                    datasets and use out-of-distribution tests.
                </p>
            </div>
            <ul class="mentions">
                <li><a rel="noreferrer" href="https://sites.google.com/vectorinstitute.ai/relm2024">Invited Talk at ReLM|AAAI 2024 by Sarath Chandar</a></li>
            </ul>
            <ul class="mentions awards">
                <li><a rel="noreferrer" href="https://openreview.net/forum?id=H1gNOeHKPS&noteId=9-OmkaOVen">Spotlight award by ICML (top 3.5%)</a></li>
            </ul>
            <ul class="links">
                <li><a rel="noreferrer" href="https://arxiv.org/abs/2310.07819">ArXiv</a></li>
                <li><a rel="noreferrer" href="https://youtu.be/Ogzi9iMGSTk">5 min. video</a></li>
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/faithfulness-measurable-models">code</a></li>
            </ul>
        </article>
        <article data-categories="publications highlights">
            <header>
                <h2 class="name">Publication</h2>
                <div class="title">Interpretability Needs a New Paradigm – pre-print</div>
                <div class="period">May 2024</div>
            </header>
            <img class="half" alt="Interpretability Needs a New Paradigm" src="img/2024-new-paradigm.svg" width="136" height="126.4" loading="lazy">
            <div class="description">
                <p>
                    The current paradigms of interpretability are called post-hoc and intrinsic.
                    Intrinsic says only models designed to be explained can be explained, often leading to
                    highly constrained models. While post-hoc says we should focus on explaining general-purpose
                    models, even though it may be challenging.
                </p>
                <p>

                    This position paper builds the idea that both paradigms have fundamental issues with how
                    they approach interpretability, and it would be much more productive to look for new
                    directions, which takes the best of both worlds. The position paper identifies 3 such
                    paradigms. 1) To design models such that faithfulness can be easily measured, 2) to
                    optimize models such that explanations become faithful, and 3) to develop models that
                    produce both a prediction and an explanation.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://arxiv.org/pdf/2405.05386">ArXiv</a></li>
            </ul>
        </article>
        <article data-categories="publications highlights">
            <header>
                <h2 class="name">Publication</h2>
                <div class="title">Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking Allegedly Important Tokens and Retraining - EMNLP Findings 2022 &amp; BlackboxNLP 2022</div>
                <div class="period">Dec 2022</div>
            </header>
            <img class="smaller" alt="Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking Allegedly Important Tokens and Retraining" src="img/2021-nlp-roar.svg" width="232" height="122" loading="lazy">
            <div class="description">
                <p>
                    Attention is a widely used component in neural networks and is often treated as an
                    explanation in the interpretability field. However, since 2019 there has been much discussion
                    on whether attention is actually a valid explanation. Much of this discussion exists
                    because it is inherently impossible to say what a correct explanation is.
                </p>
                <p>
                    This paper proposes a new indirect method for measuring if explanations are valid. It is
                    based on a previous method called <a href="https://arxiv.org/abs/1806.10758" rel="noreferrer">ROAR</a>
                    which was used for computer vision. In this paper,
                    we adapt ROAR to natural language and solve previously known issues with a new version we
                    call Recursive ROAR. Finally, we develop a scalar benchmark that will make it easy to
                    compare explanations between future papers.
                </p>
            </div>
            <ul class="mentions">
                <li><a rel="noreferrer" href="https://youtu.be/LZBrOTR1ItA">Keynote at BlackboxNLP|EMNLP 2021 by Sara Hooker</a></li>
            </ul>
            <ul class="links">
                <li><a rel="noreferrer" href="https://arxiv.org/abs/2110.08412">ArXiv</a></li>
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/nlp-roar-interpretability">code</a></li>
            </ul>
        </article>
        <article data-categories="talks">
            <header>
                <h2 class="name">Inaugural Talk</h2>
                <div class="title">Independent Research &amp; Interpretability – Cohere for AI</div>
                <div class="period">Aug 2022</div>
            </header>
            <img class="half" alt="Textual Interpretability slide" src="img/2022-cohere-for-ai.svg" width="957" height="770" loading="lazy">
            <div class="description">
                <p>
                    The Inaugural talk for the research organization Cohere for AI, a great honor! My talk is a
                    narrative about my path from independent research to PhD in interpretability. I cover many of
                    the lessons I learned during my time as an independent research, as well as some of the reasons
                    I got started with interpretability.
                </p>
                <p>
                    In the second act, I discuss contemporary challenges in interpretability to motivate new researchers.
                </p>
            </div>
            <ul class="mentions reviews">
                <li>"an honest and thought-provoking talk"</li>
                <li>"felt like a 1-on-1 mentoring session"</li>
                <li>"so genuine and inspiring!"</li>
            </ul>
            <ul class="links">
                <li><a rel="noreferrer" href="https://youtu.be/GFU4ZQ0bxV8">video</a></li>
                <li><a rel="noreferrer" href="https://docs.google.com/presentation/d/1LfeETUbzn1gXVYw4JzR-jyfxRwevMuODIYM7ZzAh8Lk/edit">slides</a></li>
            </ul>
        </article>
        <article data-categories="publications highlights">
            <header>
                <h2 class="name">Publication</h2>
                <div class="title">Post-hoc Interpretability for Neural NLP: A Survey – ACM Computing Surveys</div>
                <div class="period">Jul 2022</div>
            </header>
            <img alt="Post-hoc Interpretability for Neural NLP: A Survey" src="img/2021-survey-paper-toc.svg" width="594" height="475" loading="lazy">
            <div class="description">
                <p>
                    A survey on post-hoc interpretability methods for Natural Language Processing (NLP). The
                    survey covers 19 specific interpretability methods and cites more than 100 works. Each
                    method is categorized by how it communicates, visualized in a comparative format, and
                    its evaluation methodology is discussed.
                </p>
                <p>
                    Beyond interpretability methods, the survey covers topics on motivation for interpretability
                    and measures of interpretability. At last, we provide general insights, as well as our opinions
                    on future directions and challenges.
                </p>
            </div>
            <ul class="mentions">
                <li><a rel="noreferrer" href="https://xainlp.github.io/kddtutorial/">Tutorial at KDD2021 by the XAI-NLP group</a></li>
                <li><a rel="noreferrer" href="https://youtu.be/LZBrOTR1ItA">Keynote at BlackboxNLP|EMNLP 2021 by Sara Hooker</a></li>
                <li><a rel="noreferrer" href="https://aionai.libsyn.com/chasing-aime">The AI with AI podcast by Andy Ilachinski and Dave Broyles</a></li>
            </ul>
            <ul class="links">
                <li><a rel="noreferrer" href="https://arxiv.org/abs/2108.04840">ArXiv</a></li>
                <li><a rel="noreferrer" href="https://dl.acm.org/doi/10.1145/3546577">paper at ACM</a></li>
            </ul>
        </article>
        <article data-categories="talks">
            <header>
                <h2 class="name">Talk</h2>
                <div class="title">Importance of Textual Interpretability – LiveAI</div>
                <div class="period">Jul 2020</div>
            </header>
            <img class="smaller rounded" alt="Textual Interpretability slide" src="img/2020-liveai-talk.svg" width="1078" height="556.5" loading="lazy">
            <div class="description">
                <p>
                    Invited talk at LiveAI, on the importance of being able to explain natural language models.
                    Covering legal perspectives, the social impact of machine learning, and my work on textual
                    interpretability. From my Distill publication to my python module.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://youtu.be/Q_KM4hbrIRU">video</a></li>
                <li><a rel="noreferrer" href="https://andreasmadsen.github.io/talk-textual-interpretability/">slides</a></li>
                <!--
                    <li><a href="https://www.linkedin.com/events/learningnlp-textualheatmapswithpythonbyandreasmads/">event page</a></li>
                -->
            </ul>
        </article>
        <article data-categories="talks">
            <header>
                <h2 class="name">Panel Discussion</h2>
                <div class="title">NewInML workshop – ICML</div>
                <div class="period">Jul 2020</div>
            </header>
            <img class="smaller" alt="ICML workshop logo" src="img/2020-icml-newinml.svg" width="241.04" height="126.25" loading="lazy">
            <div class="description">
                <p>
                    Taking part in a panel discussion, on how to navigate ML academia when you are new.
                    The other panelists were Chelsea Finn (Stanford University), Shakir Mohamed (DeepMind),
                    Tong Zhang (Hong Kong SciTech), Ashley Edwards (ML Collective), and Edward Raff
                    (Booz Allen Hamilton).
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://nehzux.github.io/NewInML2020ICML/">workshop webpage</a></li>
                <li><a rel="noreferrer" href="https://icml.cc/virtual/2020/workshop/7089">recording</a></li>
            </ul>
        </article>
        <article data-categories="talks">
            <header>
                <h2 class="name">Interview</h2>
                <div class="title">Neural Arithmetic Units &amp; Independent Researcher – TWIML AI Podcast</div>
                <div class="period">Jun 2020</div>
            </header>
            <img class="smaller rounded" alt="TWIML podcast thumbnail" src="img/2020-twiml-interview.svg" width="123.8" height="44.45" loading="lazy">
            <div class="description">
                <p>
                    Interview by TWIML, on the process of developing my paper Neural Arithmetic Units. How to
                    work with limited resources, the importance of collaboration, and the struggles of being
                    an independent researcher by necessity.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://twimlai.com/talk/382">podcast</a></li>
            </ul>
        </article>
        <!-- Consider writing up my spotlight talk as its own entry -->
        <article data-categories="publications highlights talks">
            <header>
                <h2 class="name">Publication &amp; Talk</h2>
                <div class="title">Neural Arithmetic Units – ICLR 2020</div>
                <div class="period">Apr 2020</div>
            </header>
            <img alt="Neural Arithmetic Units" src="img/2019-nmu.svg" width="342" height="223" loading="lazy">
            <div class="description">
                <p>
                    Proposes two new arithmetic units (addition and multiplication), that improves
                    the state-of-the-art by 3x to 20x, over existing units such as the
                    ``Neural Arithmetic Logic Unit'' (NALU). The improvements were achieved by
                    rigorous theoretical analysis. The new units allow for more interpretable
                    models and potentially perfect extrapolation.
                </p>
                <p>
                    This received a spotlight award at ICLR, as it was among the 6% best-reviewed publications.
                </p>
            </div>
            <ul class="mentions awards">
                <li><a rel="noreferrer" href="https://openreview.net/forum?id=H1gNOeHKPS&noteId=9-OmkaOVen">Spotlight award by ICLR (top 6%)</a></li>
                <li><a rel="noreferrer" href="https://neptune.ai/blog/iclr-2020-deep-learning">Best papers award by neptune.ai</a></li>
            </ul>
            <ul class="mentions">
                <li><a rel="noreferrer" href="https://twimlai.com/talk/382">Interview by TWIML AI</a></li>
            </ul>
            <ul class="links">
                <li><a rel="noreferrer" href="https://openreview.net/forum?id=H1gNOeHKPS">paper</a></li>
                <li><a rel="noreferrer" href="https://openreview.net/forum?id=H1gNOeHKPS">peer-reviews</a></li>
                <li><a rel="noreferrer" href="https://iclr.cc/virtual_2020/poster_H1gNOeHKPS.html">spotlight talk</a></li>
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/stable-nalu">code</a></li>
            </ul>
        </article>
        <article data-categories="open_source">
            <header>
                <h2 class="name">Open Source</h2>
                <div class="title">Textual Heatmap – pip package</div>
                <div class="period">Mar 2020</div>
            </header>
            <video playsinline loop autoplay muted data-loading="lazy">
                <source data-src="img/2020-textual-heatmap.mp4" type="video/mp4">
            </video>
            <div class="description">
                <p>
                    A python library for creating the interactive textual heatmap visualization, as
                    I demonstrated in my <a href="https://distill.pub/2019/memorization-in-rnns/">Distill paper</a>.
                    This library works with Jupyter and Google Colab making it easy for researchers
                    to apply in their interpretability research.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/python-textualheatmap">code</a></li>
            </ul>
        </article>
        <article data-categories="publications highlights">
            <header>
                <h2 class="name">Publication</h2>
                <div class="title">Measuring Arithmetic Extrapolation Performance – SEDL|NeurIPS 2019</div>
                <div class="period">Dec 2019</div>
            </header>
            <img alt="Measuring Arithmetic Extrapolation Performance" src="img/2019-sedl.svg" width="113.95" height="42.602" loading="lazy">
            <div class="description">
                <p>
                    Proposes a new evaluation-criteria, with special confidence intervals, for
                    extrapolation tasks. It uses these criteria in a reproduction study of
                    the ``Neural Arithmetic Logic Unit'' (NALU), and shows that in some cases
                    its performance is drastically worse than previously assumed.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://arxiv.org/abs/1910.01888">paper</a></li>
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/stable-nalu">code</a></li>
                <li><a rel="noreferrer" href="download/2019-sedl-poster.pdf">poster</a></li>
            </ul>
        </article>
        <article data-categories="open_source">
            <header>
                <h2 class="name">Open Source</h2>
                <div class="title">lrcurve – pip package</div>
                <div class="period">Nov 2019</div>
            </header>
            <video playsinline loop autoplay muted data-loading="lazy">
                <source data-src="img/2019-lrcurve.mp4" type="video/mp4">
            </video>
            <div class="description">
                <p>
                    Creates a learning-curve plot for Jupyter/Colab notebooks that is updated in real-time.
                    This was first developed for a workshop at NodeConfEU, I later made it into its own
                    pip package.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/python-lrcurve/">code</a></li>
            </ul>
        </article>
        <article data-categories="products highlights">
            <header>
                <h2 class="name">Product</h2>
                <div class="title">AI smartwatch badge for NodeConf EU - NearForm Research</div>
                <div class="period">Nov 2019</div>
            </header>
            <picture>
                <source srcset="img/2019-watch.webp" type="image/webp">
                <source srcset="img/2019-watch.jpg" type="image/jpeg">
                <img class="smaller rounded" alt="AI smartwatch for NodeConf EU" src="img/2019-watch.jpg"  width="1600" height="1066" loading="lazy">
            </picture>
            <div class="description">
                <p>
                    Developed the hand-gesture recognition machine learning model for the IoT smartwatch badge,
                    given out at NodeConfEU 2019. The model ran on a system-on-chip using TensorFlow Lite for
                    Microprocessors. This was done in collaboration with the TensorFlow team.
                </p>
            </div>
            <ul class="mentions">
                <li><a rel="noreferrer" href="https://hackster.io/news/27a4899dc3bd">Article by hackster.io</a></li>
                <li><a rel="noreferrer" href="https://geeky-gadgets.com/hackable-smartwatch-11-11-2019/">Article by Geeky Gadgets</a></li>
                <li><a rel="noreferrer" href="https://youtu.be/NNa_xxLCJ3k">Review by Gary Explains</a></li>
            </ul>
            <ul class="links">
                <li><a rel="noreferrer" href="https://www.nearform.com/blog/banglejs-excitement-at-nodeconf-eu/">NodeConf blogpost</a></li>
                <li><a rel="noreferrer" href="https://www.nearform.com/blog/bangle-js-hackable-oss-js-and-tensorflow-smartwatch/">technical blogpost</a></li>
                <li><a rel="noreferrer" href="https://youtu.be/6BAqGNOyEhw">talk by Gordon</a></li>
            </ul>
        </article>
        <article data-categories="talks">
            <header>
                <h2 class="name">Talk</h2>
                <div class="title">Probability in TensorFlow.js – CopenhagenJS</div>
                <div class="period">Aug 2019</div>
            </header>
            <img class="smaller rounded" alt="TensorFlow.js Special" src="img/2019-tfjs-special-talk.svg" width="1556" height="571.99997" loading="lazy">
            <div class="description">
                <p>
                    Talked about my TensorFlow.js implementation of the special functions, and especially
                    how to survive a really difficult programming project, with lots of unknowns.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://andreasmadsen.github.io/talk-properbility-in-tfjs-ch1/">slides</a></li>
                <li><a rel="noreferrer" href="https://youtu.be/VP8Sa7z7R5Y">video</a></li>
            </ul>
        </article>
        <article data-categories="open_source">
            <header>
                <h2 class="name">Open Source</h2>
                <div class="title">TensorFlow.js Special Functions</div>
                <div class="period">Jul 2019</div>
            </header>
            <img class="smaller rounded" alt="TensorFlow.js Special" src="img/2019-tfjs-special.svg" width="1080" height="556" loading="lazy">
            <div class="description">
                <p>
                    Implementation for TensorFlow.js of the special functions used in probability, calculus,
                    differential equations, and more. Such as the beta, gamma, zeta, and Bessel functions.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/tfjs-special">code</a></li>
            </ul>
        </article>
        <article data-categories="talks">
            <header>
                <h2 class="name">Interview</h2>
                <div class="title">Visualizing and understanding RNNs – PracticalAI</div>
                <div class="period">Jun 2019</div>
            </header>
            <img class="half" alt="PracticalAI" src="img/2019-practical-ai.svg" width="19" height="19" loading="lazy">
            <div class="description">
                <p>
                    I was interviewed by PracticalAI on my Distill publication that became highly
                    acclaimed. I discuss the importance of interpretability and visualization. Such as
                    how we develop our intuition though interaction and the importance of testing that
                    intuition.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://changelog.com/practicalai/46">podcast</a></li>
            </ul>
        </article>
        <article data-categories="publications highlights">
            <header>
                <h2 class="name">Publication</h2>
                <div class="title">Visualizing memorization in RNNs – Distill Journal</div>
                <div class="period">Mar 2019</div>
            </header>
            <img alt="Visualizing memorization in RNNs" src="img/2019-distill.svg" width="369" height="154" loading="lazy">
            <div class="description">
                <p>
                    Proposes a visualization method for qualitatively comparing different RNN
                    architectures' ability to memorize and understand what parts of an
                    input-sentence make a prediction, which is great for interpretability.
                </p>
                <p>
                    Distill is a peer-reviewed journal, chaired by Chris Olah from OpenAI,
                    and other famous researchers.
                </p>
            </div>
            <ul class="mentions">
                <li><a rel="noreferrer" href="https://changelog.com/practicalai/46">Interview by PracticalAI</a></li>
                <li><a rel="noreferrer" href="https://youtu.be/iKrrKyeSRew">Video by Two Minute Papers</a></li>
            </ul>
            <ul class="links">
                <li><a rel="noreferrer" href="https://distill.pub/2019/memorization-in-rnns/">paper</a></li>
                <li><a rel="noreferrer" href="https://github.com/distillpub/post--memorization-in-rnns/issues">peer-reviews</a></li>
                <li><a rel="noreferrer" href="https://github.com/distillpub/post--memorization-in-rnns">code</a></li>
            </ul>
        </article>
        <article data-categories="open_source products">
            <header>
                <h2 class="name">Open Source &amp; Product</h2>
                <div class="title">Node.js Cephes library – NearForm Research</div>
                <div class="period">Sep 2018</div>
            </header>
            <img alt="Cephes" src="img/2018-cephes.svg" width="676" height="501" loading="lazy">
            <div class="description">
                <p>
                    By compiling the <a href="https://www.netlib.org/cephes/">cephes</a> library to
                    WebAssembly, this module allows JavaScript developers to use mathematical
                    special functions.
                </p>
                <p>Cephes.js have become a backbone for many of the Machine Learning projects at
                   NearForm Research.</p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://nearform.com/blog/webassembly-cephes/">blogpost</a></li>
                <li><a rel="noreferrer" href="https://github.com/nearform/node-cephes">code</a></li>
            </ul>
        </article>
        <article data-categories="open_source products">
            <header>
                <h2 class="name">Open Source &amp; Product</h2>
                <div class="title">Hidden Markov Model in TensorFlow.js – NearForm Research</div>
                <div class="period">Aug 2018</div>
            </header>
            <img class="smaller" alt="Cephes" src="img/2018-clinic-hmm.svg" width="128.69" height="50" loading="lazy">
            <div class="description">
                <p>
                    TensorFlow.js Implementation of Hidden Markov Model, that is now used filter background
                    noise from V8 runtime in Node.js from general CPU usage signal, leaving just the
                    main application CPU usage.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://clinicjs.org/blog/clinic-doctor-just-got-more-advanced-with-tensorflow-js/">blogpost</a></li>
                <li><a rel="noreferrer" href="https://github.com/nearform/node-hidden-markov-model-tf">code</a></li>
            </ul>
        </article>
        <!--
        <article>
          <header>
            <h2 class="name">Open Source</h2>
            <div class="title">Implement tf.isNaN, tf.isInf, tf.isFinite – TensorFlow.js</div>
            <div class="period">May 2019</div>
          </header>
        </article>
        -->
        <article data-categories="open_source products highlights">
            <header>
                <h2 class="name">Open Source &amp; Product</h2>
                <div class="title">Clinic.js Bubbleprof – NearForm Research</div>
                <div class="period">Jul 2018</div>
            </header>
            <video class="smaller" playsinline loop autoplay muted data-loading="lazy">
                <source data-src="img/2018-clinic-bubbleprof.mp4" type="video/mp4">
            </video>
            <div class="description">
                <p>
                    Implemented the collection runtime and analysis backend of Clinic.js Bubbleprof. The
                    currently most advanced tool for profiling and debugging asynchronous delays in Node.js.
                </p>
            </div>
            <ul class="mentions awards">
                <li><a rel="noreferrer" href="https://assets.thoughtworks.com/assets/technology-radar-vol-22-en.pdf">Technology Radar award Vol. 22 by ThoughtWorks</a></li>
            </ul>
            <ul class="links">
                <li><a rel="noreferrer" href="https://clinicjs.org/blog/introducing-bubbleprof/">blogpost</a></li>
                <li><a rel="noreferrer" href="https://github.com/nearform/node-clinic-bubbleprof">code</a></li>
                <li><a rel="noreferrer" href="https://youtu.be/DOIpzLJ1oN8">talk by Matteo &amp; David</a></li>
            </ul>
        </article>
        <article data-categories="open_source products highlights">
            <header>
                <h2 class="name">Open Source &amp; Product</h2>
                <div class="title">First release of Clinic.js (Doctor) – NearForm Research</div>
                <div class="period">Jan 2018</div>
            </header>
            <video class="smaller" playsinline loop autoplay muted data-loading="lazy">
                <source data-src="img/2018-clinic-doctor.mp4" type="video/mp4">
            </video>
            <div class="description">
                <p>
                    Implemented the collection runtime, analysis backend, and frontend of Clinic.js Doctor.
                    Clinic.js Doctor collects runtime usage data from the application runtime and uses
                    machine learning and advanced non-parametric statistics to classify data into a
                    recommendation for what tool to use next.
                </p>
                <p>
                    I was later involved in hiring and managing the team that now maintains it.
                </p>
            </div>
            <ul class="mentions">
                <li><a rel="noreferrer" href="https://developer.ibm.com/technologies/node-js/tutorials/learn-nodejs-debugging-and-profiling-node-applications/">Article by IBM Developer</a></li>
                <li><a rel="noreferrer" href="https://youtu.be/x35pOvZBJk8?t=775">Mention at TensorFlow Dev Summit keynote</a></li>
            </ul>
            <ul class="links">
                <li><a rel="noreferrer" href="https://nearform.com/blog/introducing-node-clinic-a-performance-toolkit-for-node-js-developers/">blogpost</a></li>
                <li><a rel="noreferrer" href="https://github.com/nearform/node-clinic-doctor">code</a></li>
                <li><a rel="noreferrer" href="https://youtu.be/DOIpzLJ1oN8">talk by Matteo &amp; David</a></li>
            </ul>
        </article>
        <article data-categories="publications">
            <header>
                <h2 class="name">MSc. Thesis</h2>
                <div class="title">Semi-supervised neural machine translation</div>
                <div class="period">Aug 2017</div>
            </header>
            <img alt="MSc thesis" src="img/2017-msc-thesis.svg" width="348" height="149" loading="lazy">
            <div class="description">
                <p>
                    A semi-supervised neural machine translation model for small
                    bilingual datasets. The model used the ByteNet model (Kalchbrenner, et. al.) together
                    with a beam-search marginalization approach for semi-supervised learning.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/master-thesis">code</a></li>
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/master-thesis/blob/master/thesis.pdf">thesis</a></li>
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/master-thesis/blob/master/presentation.pdf">slides</a></li>
            </ul>
        </article>
        <article data-categories="open_source">
            <header>
                <h2 class="name">Open Source</h2>
                <div class="title">Node.js core - async_hooks</div>
                <div class="period">May 2017</div>
            </header>
            <img class="half" alt="Node.js async_hooks" src="img/2017-nodejs-async-hooks.svg" width="590" height="361" loading="lazy">
            <div class="description">
                <p>
                    I was a critical part of getting the <code>async_hooks</code> module implemented in the Node.js core runtime.
                    This module allows users to monitor all asynchronous operations happening in the application.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://nodejs.org/dist/latest-v8.x/docs/api/async_hooks.html">documentation</a></li>
                <li><a rel="noreferrer" href="https://github.com/nodejs/node/pull/12892">main pull request</a></li>
            </ul>
        </article>
        <article data-categories="open_source">
            <header>
                <h2 class="name">Open Source</h2>
                <div class="title">Official TensorFlow implementation of sparsemax</div>
                <div class="period">Feb 2017</div>
            </header>
            <img class="half" alt="TensorFlow sparsemax" src="img/2017-sparsemax.svg" width="267" height="176" loading="lazy">
            <div class="description">
                <p>
                    Implemented the sparsemax operator in the TensorFlow core, as part of a course project.
                    This involved Python, C++, and CUDA.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/course-02456-sparsemax/blob/master/latex/report/report.pdf">white paper</a></li>
                <li><a rel="noreferrer" href="https://github.com/tensorflow/tensorflow/pull/6387">main pull request</a></li>
            </ul>
        </article>
        <article data-categories="open_source">
            <header>
                <h2 class="name">Open Source</h2>
                <div class="title">Dprof, asynchronous I/O profiling tool</div>
                <div class="period">Dec 2016</div>
            </header>
            <img alt="dprof" src="img/2016-dprof.svg" width="132" height="57" loading="lazy">
            <div class="description">
                <p>
                    Implemented interactive profiling software for monitoring all
                    asynchronous operations in a node.js application.
                    This used, at the time, an internal version of <code>async_hooks</code>,
                    and the tool was instrumental in debugging the <code>async_hooks</code>
                    implementation in Node.js.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://dprof.js.org/">demo</a></li>
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/dprof">code</a></li>
            </ul>
        </article>
        <article data-categories="talks">
            <header>
                <h2 class="name">Talk</h2>
                <div class="title">Benchmarking with statistics in Node.js – NodeConf EU</div>
                <div class="period">Nov 2016</div>
            </header>
            <picture>
                <source srcset="img/2016-benchmarking-nodejs.webp" type="image/webp">
                <source srcset="img/2016-benchmarking-nodejs.jpg" type="image/jpeg">
                <img class="smaller rounded" alt="benchmarking nodejs" src="img/2016-benchmarking-nodejs.jpg" width="735" height="436" loading="lazy">
            </picture>
            <div class="description">
                <p>
                    After having introduced statistics into the Node.JS open source project for their
                    benchmarking suite, I was invited to speak at NodeConf EU in Ireland.
                </p>
                <p>
                    The challenge was to communicate both how a Welch's t-test works to people that often
                    dislike mathematics, and provide the psychological background of why statistics is
                    necessary.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://andreasmadsen.github.io/talk-benchmaking-nodejs-with-statistics/">slides</a></li>
                <li><a rel="noreferrer" href="https://youtu.be/IPH4C9cHJLg">video</a></li>
            </ul>
        </article>
        <article data-categories="open_source">
          <header>
            <h2 class="name">Open Source</h2>
            <div class="title">Node.js benchmark suite</div>
            <div class="period">Jun 2016</div>
          </header>
          <img class="half" alt="Node.js async_hooks" src="img/2017-nodejs-async-hooks.svg" width="590" height="361" loading="lazy">
          <div class="description">
            <p>
                Complete refactor if the benchmark pipeline and tooling used in Node.js. This was done to add proper statistics
                to the micro benchmarks used in Node.js. A big challenge was to communicate statistical concepts to programmers,
                particularly for a large-scale open-source project which gets new contributors very frequently.
            </p>
          </div>
          <ul class="links">
            <li><a rel="noreferrer" href="https://github.com/nodejs/node/blob/main/doc/contributing/writing-and-running-benchmarks.md#running-benchmarks">documentation</a></li>
            <li><a rel="noreferrer" href="https://github.com/nodejs/node/pull/7094">main pull request</a></li>
          </ul>
        </article>
        <article data-categories="publications">
            <header>
                <h2 class="name">BSc. Thesis</h2>
                <div class="title">Story-level semantic clustering</div>
                <div class="period">Aug 2015</div>
            </header>
            <img class="smaller" alt="skip-gram paragraph model" src="img/2015-bsc.svg" width="524.41" height="372.05" loading="lazy">
            <div class="description">
                <p>
                    A comparison of paragraph2vec (a word2vec variant) and an
                    LSTM encoder-decoder (Sutskever el al.), for generating semantic vectors
                    that are precise enough to cluster documents according to the story.
                </p>
                <p>
                    The thesis also proposes a quasi-linear-time clustering algorithm,
                    useful for dated documents such as new articles.
                </p>
            </div>
            <ul class="links">
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/bachelor-code">code</a></li>
                <li><a rel="noreferrer" href="https://github.com/AndreasMadsen/bachelor-report/blob/master/Thesis.pdf">thesis</a></li>
            </ul>
        </article>
        <!--
        <article>
          <header>
            <h2 class="name">Open Source</h2>
            <div class="title">Trace</div>
            <div class="period">Mar 2014</div>
          </header>
        </article>
        <article>
          <header>
            <h2 class="name">Open Source</h2>
            <div class="title">JavaScript implementation of XorShift 128bit RNG</div>
            <div class="period">Mar 2014</div>
          </header>
        </article>
        <article>
          <header>
            <h2 class="name">Open Source</h2>
            <div class="title">JavaScript implementation of Student's t-test</div>
            <div class="period">Jul 2013</div>
          </header>
        </article>
    -->
        <article data-categories="open_source">
            <header>
                <h2 class="name">Open Source</h2>
                <div class="title">Node.js core - cluster module</div>
                <div class="period">Jun 2012</div>
            </header>
            <img class="smaller" alt="Node.js async_hooks" src="img/2012-nodejs-cluster.svg" width="249" height="68" loading="lazy">
            <div class="description">
                <p>
                    I was the main implementer of the <code>cluster</code> module for Node.js. This allowed developers to run a
                    server on multiple CPU cores. Because JavaScript is single-threaded that was big news. Today this is less relevant
                    because load balancers and containers have become the default scaling strategy.
                </p>
            </div>
            <ul class="mentions">
                <li><a rel="noreferrer" href="https://web.archive.org/web/20121109224609/http://blog.nodejs.org/2012/06/25/node-v0-8-0/">Node.js 0.8.0 announcement</a></li>
            </ul>
            <ul class="links">
                <li><a rel="noreferrer" href="https://nodejs.org/dist/latest-v8.x/docs/api/cluster.html">documentation</a></li>
            </ul>
        </article>
    </section>
    <section class="content categorized" id="contact">
        <h1 class="section-title"><span>Contact</span></h1>
        <article>
              <script>
                  (function () {
                    var a;
                    document.currentScript.insertAdjacentHTML(
                        'beforebegin',
                        '<p>Email: '+ (a = atob('YW13ZWJkaytwb3J0Zm9saW9AZ21haWwuY29t'), a.link('mailto:'+a)) + '</p>'
                    );
                  })();
              </script>
        </article>
    </section>
    <footer>
        <img id="bottom-image" src="dango.svg" alt="Bottom art, contains cute dangos figures textured as if drawn on paper." width="1089" height="388" loading="lazy">
    </footer>
    <script>
        if (window.hasOwnProperty('IntersectionObserver')) {
            document.addEventListener("DOMContentLoaded", function () {
                const observer = new IntersectionObserver(function (entries, observer) {
                    for (let video of entries) {
                        if (!video.isIntersecting) continue;
                        observer.unobserve(video.target);
                        for (let source of video.target.getElementsByTagName('source')) {
                            source.src = source.dataset.src;
                        }
                        video.target.load();
                    }
                }, { rootMargin: '200px' });

                for (let videoElem of document.querySelectorAll("video[data-loading='lazy']")) {
                    observer.observe(videoElem);
                }
            });
        }
    </script>
</body>
</html>
